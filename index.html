
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>AI4Verification</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="AI4Verification is a group in Huawei">
  <meta name="keywords" content="ai4verification">
  <meta name="author" content="Wenyi Xiao" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>Verification</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">Members</a>
    <a href="#projects" class="w3-bar-item w3-button">Introduction</a>
    <a href="#talks" class="w3-bar-item w3-button">Survey</a>
    <a href="#publications" class="w3-bar-item w3-button">Publication</a>
    <a href="#service" class="w3-bar-item w3-button">Brainstorm</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">AI4Verification</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  <!-- </div> -->
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/group_photo.png">
      <img style="width: 40%;max-width: 120px" alt="profile photo" src="images/yuanmingxuan.png">
      <img style="width: 40%;max-width: 220px" alt="profile photo" src="images/haojianye.png">
      <h1>AI4Verification</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          Many EDA applications can be abstracted into SAT problems and then directly call the SAT solver to solve them, including Model Checking (MC), Logic Synthesis, Logic Equivalence Checking (LEC), Automatic Test Pattern Generation (ATPG), etc. However, high-performance SAT solvers are often not equivalent to the fact that the actual EDA problem can be solved efficiently. The reasons include high-quality coding (modeling) methods in complex constraint scenarios, solution-friendly simplification methods, and data-matched Solver or solution algorithm selection, etc. 
        </p>
        <p class="w3-center">
          <a href="mailto:Noah_AI4EDA@gmail.com">Email</a> 
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>成员介绍</h2>
   All of us are working on SAT-related algorithms in EDA, such as Automatic Test Pattern Generation (ATPG), Logic Equivalence Checking (LEC), Model Checking (MC). We all focus on both modeling and solving in practice.
      <p><li> Dr. Mingxuan Yuan | <a style="color: #447ec9" href="https://dblp.org/pid/74/2356.html">DBLP</a>：PhD on data mining, data management, machine learning, etc. Now he is the project manager of AI4EDA in Noah's Ark Lab, Huawei. </li></p>
      <p><li> Dr. Hui-Ling Zhen | <a style="color: #447ec9" href="https://scholar.google.com.hk/citations?user=gq29DtwAAAAJ&hl=zh-CN">google scholar</a>: PhD on Numerical PDE, large scale optimization, and large scale constraint optimization. Now she is working on incremental SAT solving, ATPG, approximation in BMC, ATPG for LEC, etc.</li></p>
      <p><li> Dr. Wenyi Xiao | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=4sgCmJIAAAAJ&hl=en">google scholar</a>: PhD on data mining, recommendation system. Now she is working on adaptive LEC algorithm, and graph embedding on EDA problems. </li></p>
      <p><li> Dr. Lihao Yin | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=bS9oH_oAAAAJ&hl=en">google scholar</a>: PhD on Applied mathematics and statistics. Now he is working on incremental MC algorithms, property grouping-based verification, latch correspondence, fix-point algorithm in PDR and word-level verification, etc. </li></p>
      <p><li> Wanqian Luo | <a style="color: #447ec9" href="https://github.com/">Github</a>: luowanqian Master in CS. Now he is working on circuit SAT, parallel SAT solving, bandit for clause sharing, incremental LEC,adaptive modeling in LEC, etc. </li></p>
      <p><li> Junhua Huang | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=pFOIOJ0AAAAJ&hl=zh-CN">google scholar</a>: Master in combinatorial optimization. Now she is working on efficient reverse simulation in SAT sweeping, and related application in logic synthesis and LEC. </li></p>

 <h4><li>Some of our kindly partners:</li></h4>
      <p><li> Dr. Jianye Hao | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=FCJVUYgAAAAJ&hl=zh-CN">google scholar</a>: PhD on reinforcement learning and multi-agent system. Now he is the director of decision and reasoning lab of Noah's Ark Lab, Huawei. </li></p>
      <p><li> Dr. Yu Huang | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=acPTiEQAAAAJ&hl=en">google scholar</a>: PhD on DFT, and more than 20 years experience on industrial DFT, such as diagnosis, compression, compaction, scan chain test, etc. </li></p>
      <p><li> Dr. Naixing Wang | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=c_R21V8AAAAJ&hl=en">google scholar</a>: PhD on DFT. Several years experience on industrial DFT, such as ATPG, TPI, etc. </li></p>
      <p><li> Yingxue Zhang | <a style="color: #447ec9" href="https://scholar.google.com/citations?user=4bsYpogAAAAJ&hl=en">google scholar</a>: Years of experience on graph networks and representation learning.  </li></p>
  </div>


<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>SAT in Industrial EDA Problems</h2>
    <p class="w3-justify">
	    Boolean Satisfiability (or called SAT for short) is the problem of determining if there exists an interpretation that satisfies a given Boolean formula. In other words, it asks whether the variables of a given Boolean formula can be consistently replaced by the values TRUE or FALSE in such a way that the formula evaluates to TRUE. If this is the case, the formula is called satisfiable, otherwise, it is unsatisfiable. Modern SAT solver depends on Conflict-driven Clause Learning (CDCL) algorithm. 
    </p>

              <h4><li>Development of Boolean Satisfiability</li></h4>
        <img style="width:96%;" src="images/Timeline.png">
        <p class="w3-justify">
      Before 2012: Several research has been done on circuit SAT as well as the combination between ATPG and SAT. ATPG has shown certain advantage on solving sequential equivalence checking during the requirement-driven searching strategy and activity-based modeling method. In MC, word-level research has started. Intel has proposed a commerial ATPG engine with SAT-reasoning module. In ATPG, PASSAT has been proposed which enables the SAT-based ATPG in industrial applications. In LEC, bundle method (an incremental LEC method) has been proved the better efficiency. There are two major events: 1) one is that the SAT competition began to be normalized and is held every year after 2002; 2) the other one is that there is the  <strong> first patent</strong> (as far as our knowledge) for data-driven LEC engine, and it is worth mentioning that <strong> the improved data-driven LEC architectur has appeared in the Formality's white paper </strong> in 2021. 
      </p>
      <p class="w3-justify">
      2013-2018: 1. Cube-and-conquer was proposed for SAT solving: based on this framework, the performance of parallel proofs on some data is better than serial ones; 2. More and more improvement of SAT-based proofs focuses on encoding. 3. Algebra and theory proving has began to be used in the LEC of datapath circuit, especially for proving multiplier. 4. More learning-based proof schemes have been proposed in LEC and MC: a) Adaptive scheme selection has become a general pipeline in many patents and white paper. b) For hard bug finding cases, reinforcement learning and MDP methods have been utilized for path finding. It is worth mentioning that the <strong> first learning-based SAT solver </strong> network, or called NeuroSAT, has been proposed. The basic network consists of two parts, a GNN-based network to get the representation vector, and a classifier to predict. Its aim is to predict whether the problem is SAT or UNSAT. After that, most of the learning-aided SAT solvers follow this architecture. 
             </p>
      <p class="w3-justify">
      From 2019 to now: More and more researches are conducted on <strong> data augmentation </strong>. The key insight is to improve the quality of trained model by improving data diverity and sample complexity. More white papers on industrial verification tool, such as conformal and vso.ai, has claimed the effect of learning methods. Reverse engineering has been utilized in LEC, aiming to improve the proof efficiency of datapath circuit. Kissat has won the SAT competition in 2020. From then on, more and more SAT solvers follow Kissat's architectur. In 2022, the golden SAT solver has used bandit for algorithm selection based on the data structure of the original Kissat.
        </p> 

      <h4><li>Symbolic or Structural?</li></h4>
            <img style="width: 95%;max-width: 320px" src="images/cnfgeneration.png">
            <p class="w3-justify">
      On the one hand, SAT solvers are continuously improving their performance. The latest SAT solvers try to infer possible circuit structure information in CNF, thereby enhancing the correctness of decision-making. SAT solvers serve as the basic engines in industrial EDA, such as ATPG, LEC, MC, routing, etc. This is partly due to the efficiency of symbolic computation in dealing with NP-hard problems, especially the efficient reasoning between Boolean variables. 
      </p>

      <p class="w3-justify">
      On the other hand, The SAT problem is completely different from the domain of the EDA problem. The latter is defined on the circuit and often has scene-specific constraints, such as the diagnosis resolution and compression-aware considered in ATPG. In MC, it is often necessary to know the situation of each PO. If it is not found that a PO is unsafety (that is, corresponding to the SAT problem), the solution will be exited. Two bottlenecks often happen in SAT's applications in industrial EDA. 1) Modeling time cost much. Take ATPG as an example, the transformation time from circuit to CNF is usually longer than solving time. 2) Low reasoning efficiency due to the learning-from-mistakes framework. A lot of structural information is too difficult to embed in symbolic expressions. In the research of SAT community, a very important direction is to introduce structural information into expressions through means such as simulation (on RTLIL or netlist) in the early stage.  
       </p>

      <h4><li>SAT-related Problem in EDA</li></h4>
      <p class="w3-justify">
      We have summarized several problems that an efficient SAT-based solution may face, if you are also interested in these problems, welcome to email us.
       </p>

        <img style="width:94%;" src="images/satproblem.png"> 
       <ol>

      <p><li> <strong>Effective modeling.</strong> We aim at "effective", not only efficient, the reason lies in the possible loss of structural information of SAT boolean formulas. In this problem, we mainly consider how to preserve the structural properties of the circuit itself, and further effectively identify the implicit constraints that correctly define the search space and put them into the model.  </li></p>

      <p><li> <strong>Adaptive preprocessing.</strong> There is an underlying assumption here that, in a general-purpose solver, a smaller model usually means a relatively higher probability of being efficiently proved UNSAT, or finding a set of legal assignments. Therefore, we always hope to add a suitable pre-solution module between modeling and solving. Neither will it bring a performance burden due to additional calculations, nor will it limit the accuracy of decision-making due to the size of the model. Especially in Model Checking, we found that efficient latch correspondece or retiming and speculation technologies can always relieve the pressure of state explosion to a certain extent, thereby improving the proof or solution performance. </li></p>

      <p><li> <strong> Adaptive distributed solving scheme.</strong> From the perspective of the SAT community, the performance of the SAT solver itself is greatly improved every year. However, in industrial practice, we do find that the solution performance is not always equivalent to the ranking of the SAT competition, and different problems always have their own solvers. How to efficiently use different solvers to complete adaptive parallel or distributed systems is an important problem to be solved urgently. Furthermore, for a hard case, <strong> if any single solver cannot solve it, how to complete an efficient portfolio strategy </strong> through information interaction between different solvers is our top priority. </li></p>

      <p><li> <strong>Efficient simulation.</strong> Here we assume that we always carry out the proof flow from a high-level language to a mathematical/boolean expression. How to obtain important semantic information from higher-level models (such as RTLIL or netlist) and efficiently use semantic information to complete decision-making and search is one of the important research directions. </li></p>

      <p><li> <strong>Effective data augmentation.</strong> We certainly believe that AI can contribute to the solution and proof of SAT. However, we also admit that the current stable application of AI to industrial scenarios faces many challenges such as stability and generalization. How to  <strong> improve the quality of the current training data through data augmentation </strong>, so as to improve sample complexity and enhance generalization, is the first problem to be solved. Many people have already begun to pay attention to this direction. But from the perspective of SAT, the biggest problem we need to face is that <strong> the similarity of the model does not match the similarity of the solution space </strong>. That is to say, we can cite many examples to prove that even if the similarity of the two models has exceeded 99% (for example, only one constraint is inconsistent among the variables of tens of millions of scales), they can be a SAT problem, an UNSAT problem, and a It only takes 10 seconds to solve, while one takes more than 20,000 seconds. How to define an effective measurement to determine the similarity is a priority problem to be solved here. </li></p>

      <p><li> <strong>Pretrained model.</strong> In order to maximize the use of expert knowledge and data, we care whether there can be a pre-trained model to enhance the infrastructure in the current AI-based framework. If possible, we can migrate to different tasks through incremental training in the future, which not only effectively shortens the training time, but also completes information fusion in different directions through the model to make up for the short-sightedness and limitations of expert knowledge in local directions. </li></p>

      <p><li> <strong>Efficient online fine-tuning techniques.</strong> From the perspective generalization, we would like to further enhance the generalization by combining online fun-tuning, so as to improve the prediction accuracy of the model in different scenarios. We consider the appropriate fine-tuning indicators, efficient fine-tuning technology, etc. </li></p>

    </ol>
        
  <div class="w3-container w3-light-grey w3-padding-32" id="projects">
    <h2>Recent Progres</h2>
  <p class="w3-justify">
    <p><li> 2021-Incremental SAT-based ATPG framework with simulation-based preprocessing. Considering the effect of scale, we also implemente the cube-and-conquer to improve solving strategy. To improve the modeling efficiency, the fault clustering is also considered. The related paper has been published in ASP-DAC-2021.  </li></p>
    <p><li> 2022-Generative model, which is armed with partition and merge, has been trained for data augmentation, the  synthetic data is utilized to strenghen the learned NeuroSAT for algorithm selection in ATPG. The related paper has been published in ITC-2022. </li></p>
    <img style="width:90%;" src="images/ganforatpg.png">
    <p><li> 2022-Shift-left framework has been utilized in SAT-based ATPG. Conflict-driven Strutural Learning has been implemented in ATPG. The related paper has been published in ETS-2023. </li></p>
    <p><li> A generalized version on data augmentation is implemented in LEC. In this work, we consider to utilize the perturbation techniques to improve the similarity between synthetic and original data. More than 10% improvement on solving efficiency has been got on multiplier verification. The related paper has been reviewed in KDD-2023. </li></p>
    <img style="width:96%;" src="images/ganforlec.png">
    <p><li> A transformer-based learning-aided SAT solver has been implemented. Whether  The related paper has been submited to ICCAD-2023. </li></p>
    <p><li> Since 2021, the product white papers of many EDA companies have disclosed ML as one of the main selling points of formal verification related products. For example, Formality and Conformal both claim to use the data driven method to realize an adaptive distributed proof method based on multiple solvers. But the solver is primarily viewed as a black box, without any adaptive processing of searching as well as decision methods inside the solver.    </li></p>
    <p><li> The relationship between structural information and solving efficiency has been discussed from the perspective of representation learning. The related paper has been submited to ICCAD-2023. </li></p>
      </p>
  </div>
	
  <!-- The Talks Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Survey</h2>
	<h4><li>NeuroSAT</li></h4>
	</p>
	<p class="w3-justify">
	From 2018 to now: 1. NeuroSAT was proposed in 2018, and almost all learning-based SATs followed this pipeline; 2. In 2019, research work with data augmentation as the core began to appear. In 2022, we will also try to use data augmentation in ATPG and LEC; 3. In 2022, we propose to build a simulate DB from a global perspective, improve simulation quality, and enhance proof performance; 4. Synopsys and Cadence will have multiple formalizations in 2021-2022 The ML-driven framework is one of the main selling points in the verification-related product disclosure materials. But the solver is mainly regarded as a black box, and the main work is used for dynamic scheduling, adaptive solver or algorithm selection.         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">


	<h4><li>Neurocore</li></h4>
	</p>
	<p class="w3-justify">
	From 2018 to now: 1. NeuroSAT was proposed in 2018, and almost all learning-based SATs followed this pipeline; 2. In 2019, research work with data augmentation as the core began to appear. In 2022, we will also try to use data augmentation in ATPG and LEC; 3. In 2022, we propose to build a simulate DB from a global perspective, improve simulation quality, and enhance proof performance; 4. Synopsys and Cadence will have multiple formalizations in 2021-2022 The ML-driven framework is one of the main selling points in the verification-related product disclosure materials. But the solver is mainly regarded as a black box, and the main work is used for dynamic scheduling, adaptive solver or algorithm selection.         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">

	<h4><li>Graph-Q-SAT</li></h4>
	</p>
	<p class="w3-justify">
	From 2018 to now: 1. NeuroSAT was proposed in 2018, and almost all learning-based SATs followed this pipeline; 2. In 2019, research work with data augmentation as the core began to appear. In 2022, we will also try to use data augmentation in ATPG and LEC; 3. In 2022, we propose to build a simulate DB from a global perspective, improve simulation quality, and enhance proof performance; 4. Synopsys and Cadence will have multiple formalizations in 2021-2022 The ML-driven framework is one of the main selling points in the verification-related product disclosure materials. But the solver is mainly regarded as a black box, and the main work is used for dynamic scheduling, adaptive solver or algorithm selection.         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">


	<h4><li>G2SAT</li></h4>
	</p>
	<p class="w3-justify">
	From 2018 to now: 1. NeuroSAT was proposed in 2018, and almost all learning-based SATs followed this pipeline; 2. In 2019, research work with data augmentation as the core began to appear. In 2022, we will also try to use data augmentation in ATPG and LEC; 3. In 2022, we propose to build a simulate DB from a global perspective, improve simulation quality, and enhance proof performance; 4. Synopsys and Cadence will have multiple formalizations in 2021-2022 The ML-driven framework is one of the main selling points in the verification-related product disclosure materials. But the solver is mainly regarded as a black box, and the main work is used for dynamic scheduling, adaptive solver or algorithm selection.        </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">


  <!-- The Talks Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Survey</h2>
	<h4><li>NeuroSAT</li></h4>
	</p>
	<p class="w3-justify">
	2018年至今：1. 2018年提出NeuroSAT，后续几乎所有learning-based SAT都延续这个pipeline； 2. 2019年开始出现数据增广为核心的研究工作。2022年我们也分别尝试数据增广用于ATPG和LEC中； 3. 2022年提出从全局构建simulate DB，提高simulation质量，增强证明性能； 4. 2021-2022年Synopsys和Cadence分别有多个形式化验证相关的产品公开材料中以ML-driven框架为主要卖点之一。但主要将求解器当成黑盒，而主要工作用于动态调度、自适应求解器 or 算法选择上。         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">


	<h4><li>Neurocore</li></h4>
	</p>
	<p class="w3-justify">
	2018年至今：1. 2018年提出NeuroSAT，后续几乎所有learning-based SAT都延续这个pipeline； 2. 2019年开始出现数据增广为核心的研究工作。2022年我们也分别尝试数据增广用于ATPG和LEC中； 3. 2022年提出从全局构建simulate DB，提高simulation质量，增强证明性能； 4. 2021-2022年Synopsys和Cadence分别有多个形式化验证相关的产品公开材料中以ML-driven框架为主要卖点之一。但主要将求解器当成黑盒，而主要工作用于动态调度、自适应求解器 or 算法选择上。         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">


	<h4><li>Graph-Q-SAT</li></h4>
	</p>
	<p class="w3-justify">
	2018年至今：1. 2018年提出NeuroSAT，后续几乎所有learning-based SAT都延续这个pipeline； 2. 2019年开始出现数据增广为核心的研究工作。2022年我们也分别尝试数据增广用于ATPG和LEC中； 3. 2022年提出从全局构建simulate DB，提高simulation质量，增强证明性能； 4. 2021-2022年Synopsys和Cadence分别有多个形式化验证相关的产品公开材料中以ML-driven框架为主要卖点之一。但主要将求解器当成黑盒，而主要工作用于动态调度、自适应求解器 or 算法选择上。         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">


	<h4><li>G2SAT</li></h4>
	</p>
	<p class="w3-justify">
	2018年至今：1. 2018年提出NeuroSAT，后续几乎所有learning-based SAT都延续这个pipeline； 2. 2019年开始出现数据增广为核心的研究工作。2022年我们也分别尝试数据增广用于ATPG和LEC中； 3. 2022年提出从全局构建simulate DB，提高simulation质量，增强证明性能； 4. 2021-2022年Synopsys和Cadence分别有多个形式化验证相关的产品公开材料中以ML-driven框架为主要卖点之一。但主要将求解器当成黑盒，而主要工作用于动态调度、自适应求解器 or 算法选择上。         </p> 
 	</p> 
        <img style="width:96%;" src="images/abstract_tech.png">
  </div>


 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Publication</h2>
      <p class="w3-left-align" style="line-height:200%">
	Introduce our works.
      </p>
    <h4> AI for SAT:</h4>

    <ol>

      <p>
      <li><strong>Spatial-Channel Token Distillation for Vision MLPs</strong>
      <br>
      Yanxi Li, Xinghao Chen, Minjing Dong, Yehui Tang, <strong>Yunhe Wang</strong>, Chang Xu
      <br>
      <em>ICML</em> 2022 | <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/li22c/li22c.pdf">paper</a> 
      </p>

      <p>
      <li><strong>Federated Learning with Positive and Unlabeled Data</strong>
      <br>
      Xinyang Lin*, Hanting Chen*, Yixing Xu, Chao Xu, Xiaolin Gui, Yiping Deng, <strong>Yunhe Wang</strong>
      <br>
      <em>ICML</em> 2022 (* equal contribution) | <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/lin22b/lin22b.pdf">paper</a>
      </p>

      </ol>

      <h4> ML for SAT:</h4>

      <ol>

      <p>
      <li><strong>GhostNets on Heterogeneous Devices via Cheap Operations</strong>
      <br>
      Kai Han, <strong>Yunhe Wang</strong>, Chang Xu, Jianyuan Guo, Chunjing Xu, Enhua Wu, Qi Tian 
      <br>
      <em>IJCV</em> 2022 | <a style="color: #447ec9" href="https://link.springer.com/content/pdf/10.1007/s11263-022-01575-y.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet_d">MindSpore code</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-AI-Backbones">Pytorch code</a>
      </p>

      <p>
      <li><strong>A Survey on Visual Transformer</strong>
      <br>
      Kai Han, <strong>Yunhe Wang</strong>, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu, Yehui Tang, An Xiao, Chunjing Xu, Yixing Xu, Zhaohui Yang, Yiman Zhang, Dacheng Tao
      <br>
      <em>IEEE TPAMI</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2012.12556">paper</a> 
      </p>

      </ol>

    </p>
  </div>

 <!-- The BrainStorm Section -->												  
 <div class="w3-container w3-light-grey w3-padding-32" id="brainstorm">
    <h2>Brainstorm</h2>
      <p><li> Area Chair of <a href="https://icml.cc/Conferences/2023">ICML 2021</a>, <a href="https://nips.cc/Conferences/2022/">NeurIPS 2022</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Action Editor of <a href="https://jmlr.org/tmlr/">TMLR</a> (Transactions on Machine Learning Research).</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2020, <a href="https://mp.weixin.qq.com/s/dORL01lgFNDHgjp3KMJmiQ">Nomination for Outstanding Youth Paper Award</a>, <a href="https://worldaic.com.cn/portal/en/aboutus.html">WAIC</a></p>               
    <p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship</a></p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a></br>

  <!-- Default Statcounter code for Yunhe Wang's Homepage
  https://www.wangyunhe.site -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
